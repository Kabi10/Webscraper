name: Scrape Company Reviews

on:
  schedule:
    - cron: '0 0 * * *'  # Runs at 00:00 UTC daily
  workflow_dispatch:      # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
      with:
        fetch-depth: 0  # Fetch all history for proper git operations
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.12'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create .env file
      run: |
        echo "NEXT_PUBLIC_GOOGLE_MAPS_API_KEY=${{ secrets.GOOGLE_MAPS_API_KEY }}" > .env.local
        
    - name: Run scraper
      run: |
        echo "Starting scraper..."
        python test_scraper.py
        echo "Scraper finished"
        
    - name: Check for changes
      id: check_changes
      run: |
        git status --porcelain company_reviews_new.csv | grep "company_reviews_new.csv" || echo "No changes to commit"
        
    - name: Commit and push if changes
      if: steps.check_changes.outputs.stdout
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add company_reviews_new.csv
        git commit -m "üìä Update reviews data [skip ci]"
        git push
        
    - name: Report status
      if: always()
      run: |
        if [ ${{ job.status }} == 'success' ]; then
          echo "‚úÖ Scraper ran successfully!"
        else
          echo "‚ùå Scraper encountered an error"
        fi 